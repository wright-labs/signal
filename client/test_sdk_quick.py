"""Quick SDK test - demonstrates all three API levels.

This script shows:
1. Simple API (Level 1) - direct client methods
2. Advanced Training API (Level 2) - specialized TrainingClient
3. Advanced Inference API (Level 3) - specialized InferenceClient
"""

from unittest.mock import Mock, patch
import sys

sys.path.insert(0, "/Users/arav/Desktop/Coding/wright/signal/client")

from rewardsignal import SignalClient, TrainingClient, InferenceClient


def test_simple_api():
    """Test Level 1: Simple API."""

    print("TEST 1: SIMPLE API (Level 1)")

    # Mock the session to avoid real HTTP calls
    with patch("frontier_signal.client.requests.Session") as mock_session_class:
        mock_session = Mock()
        mock_session_class.return_value = mock_session

        # Mock response for create_run
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "run_id": "test_run_123",
            "config": {"base_model": "Qwen/Qwen2.5-3B"},
        }
        mock_session.request.return_value = mock_response

        # Initialize client
        client = SignalClient(api_key="sk-test-key")
        print("‚úì Client initialized")

        # Create run (simple API)
        run = client.create_run(base_model="Qwen/Qwen2.5-3B")
        print(f"‚úì Run created: {run.run_id}")

        # Mock forward_backward response
        mock_response.json.return_value = {
            "loss": 2.5,
            "grad_norm": 1.2,
            "step": 1,
        }

        # Train using simple API
        result = client.forward_backward(
            run_id=run.run_id,
            batch=[{"text": "Hello world"}],
        )
        print(f"‚úì Forward-backward: loss={result['loss']:.4f}, grad_norm={result['grad_norm']:.4f}")

        # Mock optim_step response
        mock_response.json.return_value = {"step": 1, "learning_rate": 5e-4}

        result = client.optim_step(run_id=run.run_id)
        print(f"‚úì Optimizer step: step={result['step']}")

        # Mock sample response
        mock_response.json.return_value = {"outputs": ["Generated text from model"]}

        outputs = client.sample(
            run_id=run.run_id,
            prompts=["The meaning of life is"],
        )
        print(f"‚úì Sample generated: {outputs[0][:50]}...")

        print("\n‚úÖ SIMPLE API TEST PASSED!\n")


def test_advanced_training_api():
    """Test Level 2: Advanced Training API."""

    print("TEST 2: ADVANCED TRAINING API (Level 2)")

    with patch("frontier_signal.client.requests.Session") as mock_session_class:
        mock_session = Mock()
        mock_session_class.return_value = mock_session

        client = SignalClient(api_key="sk-test-key")

        # Get specialized training client
        training = client.training(run_id="test_run_123", timeout=7200)
        print(f"‚úì Training client created (timeout={training.timeout}s)")

        # Mock training responses
        mock_response = Mock()
        mock_response.status_code = 200
        mock_session.request.return_value = mock_response

        # Simulate training loop with decreasing loss
        losses = [2.0, 1.5, 1.2, 0.9, 0.7]

        print("\nTraining loop:")
        for i, loss in enumerate(losses):
            # Mock forward_backward
            mock_response.json.return_value = {
                "loss": loss,
                "grad_norm": loss * 0.5,
            }

            result = training.forward_backward([{"text": f"batch {i}"}])
            print(f"  Step {i + 1}: loss={result['loss']:.4f}, grad_norm={result['grad_norm']:.4f}")

            # Mock optim_step
            mock_response.json.return_value = {"step": i + 1}
            training.optim_step()

        # Check metrics
        metrics = training.get_metrics()
        print("\n‚úì Training metrics:")
        print(f"  - Current step: {metrics['current_step']}")
        print(f"  - Average loss: {metrics['avg_loss']:.4f}")
        print(f"  - Loss history: {len(metrics['loss_history'])} steps")
        print(f"  - Average grad norm: {metrics['avg_grad_norm']:.4f}")

        # Test train_batch convenience method
        mock_response.json.return_value = {"loss": 0.5, "grad_norm": 0.3}
        with patch.object(training, "optim_step", return_value={"step": 6}):
            result = training.train_batch([{"text": "convenience test"}])
            print(f"\n‚úì train_batch() convenience method: loss={result['loss']:.4f}")

        # Test save checkpoint
        mock_response.json.return_value = {"artifact_url": "s3://bucket/checkpoint.pt"}
        result = training.save_checkpoint(mode="adapter")
        print(f"‚úì Checkpoint saved: {result['artifact_url']}")

        print("\n‚úÖ ADVANCED TRAINING API TEST PASSED!\n")


def test_advanced_inference_api():
    """Test Level 3: Advanced Inference API."""

    print("TEST 3: ADVANCED INFERENCE API (Level 3)")

    with patch("frontier_signal.client.requests.Session") as mock_session_class:
        mock_session = Mock()
        mock_session_class.return_value = mock_session

        client = SignalClient(api_key="sk-test-key")

        # Get specialized inference client
        inference = client.inference(
            run_id="test_run_123",
            step=100,
            batch_size=32,
        )
        print(
            f"‚úì Inference client created (step={inference.step}, batch_size={inference.batch_size})"
        )

        # Mock inference responses
        mock_response = Mock()
        mock_response.status_code = 200
        mock_session.request.return_value = mock_response

        # Test single sample
        mock_response.json.return_value = {
            "outputs": ["This is a generated response about machine learning."]
        }

        outputs = inference.sample(
            prompts=["What is machine learning?"],
            max_tokens=50,
        )
        print(f"‚úì Single sample: {outputs[0][:60]}...")

        # Test batch sample
        mock_response.json.return_value = {"outputs": [f"Response {i + 1}" for i in range(10)]}

        prompts = [f"Prompt {i + 1}" for i in range(10)]
        outputs = inference.batch_sample(prompts, max_tokens=50)
        print(f"‚úì Batch sample: {len(outputs)} outputs generated")

        # Test caching
        inference.enable_cache()
        print("‚úì Cache enabled")

        # First call
        mock_response.json.return_value = {"outputs": ["Cached response"]}
        inference.sample(["Same prompt"], max_tokens=50)

        # Second call (should use cache)
        inference.sample(["Same prompt"], max_tokens=50)

        stats = inference.get_cache_stats()
        print(f"‚úì Cache working: {stats['cache_size']} items cached")

        # Test checkpoint comparison
        inference_early = client.inference(run_id="test_run_123", step=10)
        inference_late = client.inference(run_id="test_run_123", step=1000)

        mock_response.json.return_value = {"outputs": ["Early checkpoint response"]}
        output_early = inference_early.sample(["Test"], max_tokens=50)

        mock_response.json.return_value = {"outputs": ["Late checkpoint response"]}
        output_late = inference_late.sample(["Test"], max_tokens=50)

        print("‚úì Checkpoint comparison:")
        print(f"  - Step 10: {output_early[0][:40]}...")
        print(f"  - Step 1000: {output_late[0][:40]}...")

        print("\n‚úÖ ADVANCED INFERENCE API TEST PASSED!\n")


def test_progressive_disclosure():
    """Test progressive disclosure pattern."""

    print("TEST 4: PROGRESSIVE DISCLOSURE PATTERN")

    with patch("frontier_signal.client.requests.Session") as mock_session_class:
        mock_session = Mock()
        mock_session_class.return_value = mock_session

        mock_response = Mock()
        mock_response.status_code = 200
        mock_session.request.return_value = mock_response

        # Level 1: Beginner - direct client methods
        print("\nLevel 1 (Beginner): Direct client methods")
        client = SignalClient(api_key="sk-test-key")
        mock_response.json.return_value = {"run_id": "test_run", "config": {}}
        run = client.create_run(base_model="Qwen/Qwen2.5-3B")

        mock_response.json.return_value = {"loss": 1.0}
        client.forward_backward(run.run_id, [{"text": "test"}])
        print("  ‚úì Using: client.forward_backward()")

        # Level 2: Intermediate - SignalRun wrapper
        print("\nLevel 2 (Intermediate): SignalRun wrapper")
        run.forward_backward([{"text": "test"}])
        print("  ‚úì Using: run.forward_backward()")

        # Level 3: Advanced - Specialized clients
        print("\nLevel 3 (Advanced): Specialized clients")
        _ = client.training(run.run_id)
        print("  ‚úì Using: client.training().forward_backward()")

        _ = client.inference(run.run_id)
        print("  ‚úì Using: client.inference().sample()")

        print("\n‚úÖ PROGRESSIVE DISCLOSURE TEST PASSED!\n")


def test_type_safety():
    """Test type safety with specialized clients."""

    print("TEST 5: TYPE SAFETY")

    with patch("frontier_signal.client.requests.Session") as mock_session_class:
        mock_session = Mock()
        mock_session_class.return_value = mock_session

        client = SignalClient(api_key="sk-test-key")

        # Get specialized clients
        training = client.training(run_id="test_run")
        inference = client.inference(run_id="test_run")

        # Check types
        assert isinstance(training, TrainingClient), "training should be TrainingClient"
        assert isinstance(inference, InferenceClient), "inference should be InferenceClient"
        print("‚úì Type checking passed")

        # Check training has training methods
        assert hasattr(training, "forward_backward")
        assert hasattr(training, "optim_step")
        assert hasattr(training, "train_batch")
        assert hasattr(training, "train_epoch")
        assert hasattr(training, "get_metrics")
        print("‚úì TrainingClient has correct methods")

        # Check inference has inference methods
        assert hasattr(inference, "sample")
        assert hasattr(inference, "batch_sample")
        assert hasattr(inference, "enable_cache")
        assert hasattr(inference, "get_cache_stats")
        print("‚úì InferenceClient has correct methods")

        # Check optimized defaults
        assert training.timeout == 3600, "Training should have 1h timeout"
        assert training.max_retries == 3, "Training should have 3 retries"
        print("‚úì TrainingClient has correct defaults (timeout=3600s, retries=3)")

        assert inference.timeout == 30, "Inference should have 30s timeout"
        assert inference.max_retries == 5, "Inference should have 5 retries"
        print("‚úì InferenceClient has correct defaults (timeout=30s, retries=5)")

        print("\n‚úÖ TYPE SAFETY TEST PASSED!\n")


def main():
    """Run all SDK tests."""
    print("\n")
    print("‚ïî" + "=" * 78 + "‚ïó")
    print("‚ïë" + " " * 20 + "FRONTIER SIGNAL SDK TEST SUITE" + " " * 28 + "‚ïë")
    print("‚ïö" + "=" * 78 + "‚ïù")
    print("\n")

    try:
        test_simple_api()
        test_advanced_training_api()
        test_advanced_inference_api()
        test_progressive_disclosure()
        test_type_safety()

        print("\n")
        print("‚ïî" + "=" * 78 + "‚ïó")
        print("‚ïë" + " " * 30 + "ALL TESTS PASSED! ‚úÖ" + " " * 29 + "‚ïë")
        print("‚ïö" + "=" * 78 + "‚ïù")
        print("\n")

        print("Summary:")
        print("  ‚úì Simple API (Level 1) - Works")
        print("  ‚úì Advanced Training API (Level 2) - Works")
        print("  ‚úì Advanced Inference API (Level 3) - Works")
        print("  ‚úì Progressive Disclosure Pattern - Works")
        print("  ‚úì Type Safety - Works")
        print("\nüöÄ SDK is production-ready!\n")

    except Exception as e:
        print(f"\n‚ùå TEST FAILED: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
