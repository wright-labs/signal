models:
  # Llama models
  - name: "meta-llama/Llama-3.2-1B"
    framework: "transformers"
    gpu: "l40s:1"
    family: "llama"
  - name: "meta-llama/Llama-3.2-3B"
    framework: "transformers"
    gpu: "l40s:1"
    family: "llama"
  - name: "meta-llama/Llama-3.1-8B"
    framework: "transformers"
    gpu: "a100-80gb:1"
    family: "llama"
  - name: "meta-llama/Llama-3.1-8B-Instruct"
    framework: "transformers"
    gpu: "a100-80gb:1"
    family: "llama"
  - name: "meta-llama/Llama-3.1-70B"
    framework: "transformers"
    gpu: "a100-80gb:4"
    family: "llama"
  - name: "meta-llama/Llama-3.3-70B-Instruct"
    framework: "transformers"
    gpu: "a100-80gb:4"
    family: "llama"

  # Gemma models
  - name: "google/gemma-2-2b"
    framework: "transformers"
    gpu: "l40s:1"
    family: "gemma"
  - name: "google/gemma-2-9b"
    framework: "transformers"
    gpu: "a100-80gb:1"
    family: "gemma"
  - name: "unsloth/gemma-2-9b-it-bnb-4bit"
    framework: "transformers"
    gpu: "a100-80gb:1"
    family: "gemma"

  # Qwen models
  - name: "Qwen/Qwen2.5-3B"
    framework: "transformers"
    gpu: "l40s:1"
    family: "qwen"
  - name: "Qwen/Qwen2.5-7B"
    framework: "transformers"
    gpu: "a100-80gb:1"
    family: "qwen"
  - name: "Qwen/Qwen2.5-14B"
    framework: "transformers"
    gpu: "a100-80gb:2"
    family: "qwen"
  - name: "Qwen/Qwen2.5-32B"
    framework: "transformers"
    gpu: "a100-80gb:4"
    family: "qwen"

